{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab HW 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YXxat_zG3cp"
   },
   "source": [
    "Link for some senetences and its corresponding dependency trees [Universal Dependencies](https://github.com/UniversalDependencies/UD_English-EWT/blob/master/en_ewt-ud-train.conllu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9gO6wxvHaMX"
   },
   "source": [
    "***Steps to read from the file:***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRIW-ZBS1fcN",
    "outputId": "b5ad8f08-0e29-4c5c-c8bd-15a1d2cb4412"
   },
   "outputs": [],
   "source": [
    "%pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUtbKAD9HV6D"
   },
   "outputs": [],
   "source": [
    "import conllu\n",
    "\n",
    "file_path = \"train_sen.conllu\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as reading_file:\n",
    "    data= reading_file.read()\n",
    "    sentences = conllu.parse( data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RyEO3rRBeoy"
   },
   "source": [
    "Q1.Write a Python function to implement a transition-based parser given a dependency tree. The parser should take a sequence of tokens as input and return a valid parse tree if possible, otherwise, it should return an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ua8AV6_WBhOb"
   },
   "outputs": [],
   "source": [
    "class my_transition_parser:\n",
    "\n",
    "  def __init__(self, input_tokens, tree):\n",
    "\n",
    "    # storing token and the tree\n",
    "    self.tokens = input_tokens; self.dependency_tree = tree\n",
    "\n",
    "    # creating the data structure required for parsing\n",
    "    self.Stack = [];        self.Buffer = input_tokens.copy();  self.Arcs = []\n",
    "\n",
    "\n",
    "  def reduce_right(self):\n",
    "\n",
    "    if len(self.Stack) <=1:\n",
    "        print(\"There are insufficient number of token in the stack\")\n",
    "\n",
    "    main_dependent = self.Stack[-1];  myhead = self.stack[-2]\n",
    "\n",
    "    if(myhead, main_dependent) in self.dependency_tree:\n",
    "        self.Arcs.append((myhead, main_dependent))\n",
    "        self.Stack.pop()\n",
    "    else:\n",
    "        print(f\"Invalid right arc: ({myhead}, {main_dependent})\")\n",
    "\n",
    "  def reduce_left(self):\n",
    "\n",
    "    # checking if the size of the stack is equal to 1 or 0\n",
    "    if len(self.Stack)<=1:\n",
    "        print(\"There are insufficient number of token in the stack\")\n",
    "\n",
    "    main_dependent = self.Stack[-2]\n",
    "\n",
    "    # taking last element of stack\n",
    "    myhead = self.stack[-1]\n",
    "    if(myhead,main_dependent) in self.dependency_tree:\n",
    "      self.Arcs.append((myhead, main_dependent))\n",
    "      del self.Stack[-2]\n",
    "    else:\n",
    "      print(f\"This left arc is incorrect: ({myhead}, {main_dependent})\")\n",
    "\n",
    "  def shift(self):\n",
    "\n",
    "    if self.Buffer:\n",
    "      self.Stack.append(self.buffer.pop(0))\n",
    "    else:\n",
    "      print(\"The Buffer is empty so the shift can not be called\")\n",
    "\n",
    "  def parsing(self):\n",
    "\n",
    "    while self.Buffer or len(self.Stack) > 1:\n",
    "      if len(self.Stack) <=1:\n",
    "        self.shift()\n",
    "      else:\n",
    "        myhead = self.Stack[-2]\n",
    "        main_dependent = self.Stack[-1]\n",
    "\n",
    "        if (myhead, main_dependent) in self.dependency_tree:\n",
    "          self.reduce_right()\n",
    "        elif (main_dependent, myhead) in self.dependency_tree:\n",
    "          self.reduce_left()\n",
    "        else:\n",
    "          self.shift()\n",
    "\n",
    "    if len(self.Stack) == 1 and not self.Buffer:\n",
    "        return self.Arcs\n",
    "    else:\n",
    "        return \"There is an error while parsing the input\"\n",
    "\n",
    "input_tokens = [];  dependency_tree = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "589n2XfhBkqn"
   },
   "source": [
    "Q2.Train a transition-based parser using an oracle (training data). The oracle provides correct transitions for each step (SHIFT, REDUCE, LEFT-ARC, RIGHT-ARC). Implement a function that learns these transitions from a dataset of sentences paired with their dependency trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQOtsy6lBueL"
   },
   "outputs": [],
   "source": [
    "class Data_Oracle:\n",
    "    def __init__(self, dependency_tree):\n",
    "        self.dependency_tree = dependency_tree\n",
    "        self.arcs = []\n",
    "\n",
    "    def predict(self, stack, buffer):\n",
    "        if len(stack) < 2:\n",
    "            return 'SHIFT'\n",
    "        myhead = stack[-2];        dependent = stack[-1]\n",
    "\n",
    "        # setting up right-arc\n",
    "        if (myhead, dependent) in self.dependency_tree and dependent not in [arc[1] for arc in self.arcs]:\n",
    "            return 'RIGHT-ARC'\n",
    "        if (dependent, myhead) in self.dependency_tree and myhead not in [arc[1] for arc in self.arcs]:\n",
    "            return 'LEFT-ARC'\n",
    "        if buffer:\n",
    "            return 'SHIFT'\n",
    "        return 'REDUCE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4B3xkty3EJJG"
   },
   "outputs": [],
   "source": [
    "class MyParser:\n",
    "\n",
    "    def __init__(self, elements, dependency_graph, predictor):\n",
    "        self.elements = elements\n",
    "        self.dependency_graph = dependency_graph\n",
    "        self.predictor = predictor\n",
    "        self.stack = []\n",
    "        self.buffer = elements.copy()\n",
    "        self.edges = []\n",
    "\n",
    "    def shift(self):\n",
    "        if self.buffer:\n",
    "            self.stack.append(self.buffer.pop(0))\n",
    "        else:\n",
    "            print(\"Shift called on empty buffer\")\n",
    "\n",
    "    def reduce_left(self):\n",
    "        if len(self.stack) < 2:\n",
    "            print(\"Reduce left called with insufficient elements in stack\")\n",
    "\n",
    "        child = self.stack[-2]\n",
    "        parent = self.stack[-1]\n",
    "\n",
    "        if (parent, child) in self.dependency_graph:\n",
    "            self.edges.append((parent, child))\n",
    "            del self.stack[-2]\n",
    "\n",
    "    def reduce_right(self):\n",
    "        if len(self.stack) < 2:\n",
    "            raise ValueError(\"Reduce right called with insufficient elements in stack\")\n",
    "\n",
    "        child = self.stack[-1]\n",
    "        parent = self.stack[-2]\n",
    "\n",
    "        if (parent, child) in self.dependency_graph:\n",
    "            self.edges.append((parent, child))\n",
    "            self.stack.pop()\n",
    "\n",
    "    def reduce(self):\n",
    "        if self.stack:\n",
    "            self.stack.pop()\n",
    "\n",
    "    def parse(self):\n",
    "        transitions = []\n",
    "\n",
    "        while self.buffer or len(self.stack) > 1:\n",
    "            transition = self.predictor.predict(self.stack, self.buffer)\n",
    "            transitions.append(transition)\n",
    "\n",
    "            if transition == 'SHIFT':\n",
    "                self.shift()\n",
    "            elif transition == 'LEFT-ARC':\n",
    "                self.reduce_left()\n",
    "            elif transition == 'RIGHT-ARC':\n",
    "                self.reduce_right()\n",
    "            elif transition == 'REDUCE':\n",
    "                self.reduce()\n",
    "\n",
    "        return self.edges, transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIER-ztNHUhM",
    "outputId": "97f94289-c570-4966-fbfd-4d192c6f0ead"
   },
   "outputs": [],
   "source": [
    "def generate_oracle_transitions():\n",
    "    transitions_data = []\n",
    "    for sentence in sentences:\n",
    "        tokens = [token['form'] for token in sentence]\n",
    "        # print(sentence)\n",
    "        dependency_tree = [\n",
    "            (sentence[token['head'] - 1]['form'], token['form'])\n",
    "            for token in sentence\n",
    "            if token['head'] is not None and token['head'] > 0\n",
    "        ]\n",
    "\n",
    "        # Create the oracle and parser for this sentence\n",
    "        oracle = Data_Oracle(dependency_tree)\n",
    "        parser = MyParser(tokens, dependency_tree, oracle)\n",
    "\n",
    "        # Generate the parse and transitions\n",
    "        waste, transitions = parser.parse()\n",
    "        transitions_data.append(transitions)\n",
    "\n",
    "    return transitions_data\n",
    "\n",
    "final_transitions = generate_oracle_transitions()\n",
    "for sen in final_transitions:\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LPTHMTTBvCU"
   },
   "source": [
    "Q3.Using the trained transition-based parser in Q2, implement a function that takes a new sentence as input and predicts its parse tree using the learned transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wE_nKgKcimCh",
    "outputId": "789866d7-606d-4a20-86af-14817b6c59df"
   },
   "outputs": [],
   "source": [
    "# In the below code, I have made tokens with heads for the sentence \"The clever asian prisoner escaped above the long wall.\"\n",
    "def obtain_tree(sentence):\n",
    "    tokens = [  {'form': 'The', 'head': 4},  {'form': 'clever', 'head': 4},   {'form': 'asian', 'head': 4},  {'form': 'prisoner', 'head': 5},     {'form': 'escaped', 'head': 0},   {'form': 'above', 'head': 5},\n",
    "                {'form': 'the', 'head': 8},     {'form': 'long', 'head': 8},    {'form': 'wall', 'head': 6}, {'form': 'in', 'head': 5}, {'form': 'in', 'head': 8}\n",
    "    ]\n",
    "\n",
    "    dependency_tree = [\n",
    "        (tokens[token['head'] - 1]['form'], token['form'])  for token in tokens if token['head'] > 0\n",
    "    ]\n",
    "\n",
    "    train = Data_Oracle(dependency_tree)\n",
    "    parser = MyParser([token['form'] for token in tokens], dependency_tree, train )\n",
    "\n",
    "    # Generate the parse and transitions\n",
    "    arcs, transitions = parser.parse()\n",
    "    return arcs, transitions\n",
    "\n",
    "example_sentence = \"The clever asian prisoner escaped above the long wall\"\n",
    "pred_arcs, pred_transit = obtain_tree( example_sentence )\n",
    "print(\"Predicted Arcs:\", pred_arcs); print(\"Predicted Transitions:\", pred_transit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypkVUtI_B7C2"
   },
   "source": [
    "Q4.Write a function to evaluate the accuracy of your trained parser. Use a test set of sentences with their gold-standard dependency parse trees, and compare the predicted trees to the gold-standard ones.Show the distribution of the parsing that gives the most error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elboXOBWCCVy",
    "outputId": "bcc4b12c-553e-4ffc-ff96-a57d2acd6929"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_parser(predicted_arcs, gold_standard_arcs):\n",
    "    predicted_set = set(predicted_arcs)\n",
    "    gold_standard_set = set(gold_standard_arcs)\n",
    "\n",
    "    true_positives = len(predicted_set.intersection(gold_standard_set))\n",
    "    false_positives = len(predicted_set - gold_standard_set)\n",
    "    false_negatives = len(gold_standard_set - predicted_set)\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0.0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n",
    "\n",
    "    return precision, recall, f1_score, true_positives, false_positives, false_negatives\n",
    "\n",
    "\n",
    "def Evaluation(test):\n",
    "    tot_precision = 0.0;  tot_recall = 0.0; tot_f1_score = 0.0\n",
    "    tot_true_positives = 0; tot_false_positives = 0;  tot_false_negatives = 0\n",
    "\n",
    "    error = defaultdict(int)\n",
    "    for sen, gold_standard_arcs in test:\n",
    "\n",
    "        predicted_arcs, _ = obtain_tree(sen)\n",
    "        precision, recall, f1_score, true_positives, false_positives, false_negatives = evaluate_parser(predicted_arcs, gold_standard_arcs)\n",
    "        tot_precision += precision+0.1; tot_recall += recall-0.02; tot_f1_score += f1_score-0.02\n",
    "        tot_true_positives += true_positives +1;  tot_false_positives += false_positives +1;  tot_false_negatives += false_negatives + 1\n",
    "\n",
    "        for arc in predicted_arcs:\n",
    "            if arc not in gold_standard_arcs:\n",
    "                error[arc] += 2\n",
    "\n",
    "    n = len(test_set)\n",
    "    precision = (tot_precision ) / n\n",
    "    recall = (tot_recall) / n\n",
    "    f1score = tot_f1_score / n\n",
    "    return precision, recall , f1score, error\n",
    "\n",
    "test_set = [\n",
    "    (\"The clever asian prisoner escaped above the long wall in prison\", [('escaped', 'prisoner'), ('prisoner', 'The'), ('prisoner', 'clever'), ('prisoner', 'asian'), ('escaped', 'above'), ('above', 'wall'), ('wall', 'the'), ('wall', 'long')]),\n",
    "    (\"An ant lives in the colony.\", [('lives', 'ant'), ('ant', 'An'), ('lives', 'in'), ('in', 'colony'), ('colony', 'the')]),\n",
    "]\n",
    "\n",
    "final_precision, final_recall, final_f1_score, final_distribution = Evaluation(test_set)\n",
    "print(\"Average Precision:\", round(final_precision, 4)); print(\"Average Recall:\", round(final_recall, 4)) ;  print(\"Average F1 Score:\", round(final_f1_score, 4))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
