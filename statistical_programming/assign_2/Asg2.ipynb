{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## __Imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as mt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Functions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Poisson Distribution_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------  GENERAL FUNCTIONS  ------------------------------------------------------------\n",
    "# MEAN\n",
    "def arr_mean(arr:np.array)->float:\n",
    "  \"\"\"_Summary_\n",
    "    This returns the mean of all the values which are present in the numpy array.\n",
    "  Args:\n",
    "    arr (np.array): This is an array containing the values for which mean has to be taken out.\n",
    "\n",
    "  Returns:\n",
    "    float: A floating integer is returned which is the mean of the values provided in the numpy array.\n",
    "  \"\"\"\n",
    "\n",
    "  sum:int =0; sz:int = len(arr)  \n",
    "  \n",
    "  for i in range(sz):\n",
    "    sum += arr[i]\n",
    "    \n",
    "  return sum/sz\n",
    "\n",
    "\n",
    "# VARIANCE\n",
    "def arr_variance( arr:np.array , mean:float )->float:\n",
    "  \"\"\"_Summary_\n",
    "    This returns the variance of all the values which are present in the numpy array.\n",
    "  Args:\n",
    "    arr (np.array): This is an array containing the values for which mean has to be taken out.\n",
    "    mean (float): This is the mean of the values present in the array.\n",
    "  Returns:\n",
    "    float: A floating integer is returned which is the variance of the values provided in the numpy array.\n",
    "  \"\"\"\n",
    "\n",
    "  sum:int = 0; sz=len(arr)\n",
    "  \n",
    "  for i in range(sz):\n",
    "    sum += (arr[i]-mean)**2\n",
    "  \n",
    "  return (sum)/sz\n",
    "\n",
    "\n",
    "# -------------------------------------------------------  UNIVARIATE  -----------------------------------------------------------------\n",
    "# Function which follows altered cdf of Poisson distribution\n",
    "def changed_Poisson(X:int, lamda:int)->float:\n",
    "\t\"\"\"This is a function which returns the poission distribution.\"\"\"\n",
    "\n",
    "\tf_x = ( (lamda**X)/mt.factorial(X) )\n",
    "\treturn f_x\n",
    "\n",
    "# Function which follows the altered cdf of Poisson distribution\n",
    "def Poisson_cdf( lim:int , LAMDA:int )->np.array:\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      lim (int): This is the limit upto which the numpy array is to be made\n",
    "\n",
    "  Returns:\n",
    "      np.array: This is the numpy array which has the index number as the realisation of the random variable and the value in the array as the cdf upto that value.\n",
    "\n",
    "  It returns an array which contains the cdf value for the (index + 1) range.\n",
    "  \"\"\"\n",
    "\n",
    "  arr =[ 0 ]\n",
    "  for i in range(1,lim,1):\n",
    "    arr.append( arr[i-1] + changed_Poisson(i,LAMDA) )\n",
    "  cdf=np.array(arr)\n",
    "  \n",
    "  return cdf\n",
    "\n",
    "# Function which works as the inverse for the Poisson distribution\n",
    "def Poisson_value( cdf:np.array, prob:float ,lamda:int )->int:\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "    cdf (np.array): This is the cdf array for a particular distribution.\n",
    "    prob (float): This is an specific probability value which is in the range of 0 to 1. \n",
    "\n",
    "  Returns:\n",
    "    int: This is the realisation of the random variable.\n",
    "  \"\"\"\n",
    "\n",
    "  sz: int =len(cdf)\n",
    "  for i in range(sz):\n",
    "    if( prob/mt.exp(0-lamda) < cdf[i]):\n",
    "      return i\n",
    "    \n",
    "  return 0\n",
    "\n",
    "# Function which gives randomly generated numbers which follow gaussian distribution\n",
    "def ITS_poisson( num_samples:int, prestored_samples:int, lamda:int )->np.array:\n",
    "  \"\"\"_Summary_\n",
    "  \n",
    "  Args:\n",
    "    num_samples (int): This is the toal number of samples taken for the transformation from uniform to gaussian function.\n",
    "    prestored_samples (int): This is the total number of prestored samples taken.\n",
    "    lamda (int): This is the lamda taken for the gaussian distribution.\n",
    "\n",
    "  Returns:\n",
    "    np.array: This is the array which contains the transformed uniform random number which now follow normal/gaussian distribution \n",
    "  \"\"\"\n",
    "  \n",
    "  CAL= Poisson_cdf( prestored_samples ,lamda )\n",
    "  \n",
    "  # Generating uniform random numbers\n",
    "  dp: np.array = np.random.uniform(0, 1, num_samples)\n",
    "  dataset:np.array = np.array( [ Poisson_value(CAL,i,lamda) for i in dp ] )\n",
    "  \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Gaussian Distribution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ITS_gaussian(num_samples, mean:tuple, Covariance:list  ):\n",
    "  \"\"\"_Summary_\n",
    "    This returns an array with random numbers which follow the standard normal distribution.\n",
    "    \n",
    "    Here, Inverse transform sampling uses the Box-muller transformation to convert the uniform random samples to the standard normal distribution. The link for the definition and implementation of the Box-muller transformation has been given in the refrences.\n",
    "\n",
    "  Args:\n",
    "      samples (int): This is the number which tells about how many samples do we need \n",
    "\n",
    "  Returns:\n",
    "      tuple: This returns a tuple of bivariate tuples which give gaussian distribution following values. \n",
    "  \"\"\"\n",
    "  \n",
    "  var=( Covariance[0][0], Covariance[1][1] )\n",
    "  corr=Covariance[0][1]/(np.sqrt(Covariance[0][0]*Covariance[1][1]))\n",
    "  \n",
    "  u1 =  np.random.uniform(0,1,num_samples)\n",
    "  u2 = np.random.uniform(0,1,num_samples )\n",
    "\n",
    "  # Generating two bivariate standard normal disibutions\n",
    "  z1 = np.sqrt( -2  * np.log( u1 ) ) * np.cos(2 * np.pi * u2)\n",
    "  z2 =  np.sqrt(-2 * np.log(u1)) *  np.sin(2 * np.pi * u2)\n",
    "  \n",
    "  # Generate correlated variables\n",
    "  x1 = mean[0] + np.sqrt( var[0] ) * z1\n",
    "  x2 = mean[1] + Covariance[0][1] /np.sqrt(var[0])*z1 + np.sqrt(var[1]-Covariance[0][1]**2 / var[0])*z2\n",
    "\n",
    "  # Creating the Dataset\n",
    "  data:np.array=[]\n",
    "  for i in range( len(x1) ):\n",
    "    data =data+[(x1[i],x2[i])]\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# __Question 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Introduction__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The Question consisted the following parts:\n",
    "  -  #### `Q`: Generate a dataset representing the number of customer arrivals per hour in a store, assuming a Poisson distribution with a mean arrival rate of 5. \n",
    "      #### Use Python to create a histogram to visualize the distribution. Calculate the mean and variance of the generated dataset and explain how they relate to the parameters of the Poisson distribution.\n",
    "  - #### `A`: Here the mean arrival rate is the mean for the distribution and also the _lamda_ for the _Poisson distribution_. Using this, we calculate the mean and variance of the distribution.\n",
    "  ---\n",
    "  - #### `Q`: Generate a bivariate dataset with two features (e.g., height and weight) assuming a multivariate Gaussian distribution with given means μ1 = 65, μ2 = 150 and covariance matrix Σ [[25, 10], [10, 36]]. \n",
    "      #### Visualize the data using a scatter plot in Python. Discuss the patterns in the plot and how they correspond to the parameters of the multivariate Gaussian distribution.\n",
    "  - #### `A`: Here, the Covariance matrix can be expressed in terms of variance and correlation for the height and weight. After this we can apply Box-Muller Technique.\n",
    "  ---\n",
    "  - #### `Q`: Generate a dataset for a univariate scenario (e.g., sales per day) and a bivariate scenario (e.g., temperature and sales) using both Poisson and multivariate Gaussian distributions. Create visualizations for each dataset using appropriate plots for each distribution (e.g., histogram for Poisson, scatter plot for multivariate Gaussian). Compare and contrast the visualizations, explaining how the characteristics of each distribution are reflected in the plots\n",
    "  - #### `A`: Here we take random values for mean and variance ensuring the negative value criteria for sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __A__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Methodology__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The main idea used here is to get the cdf of random variable for a large number of realisations of the random variable `X` which follows the Poisson distibution.\n",
    "\n",
    "- #### The Poisson distribution can be represented by the pmf as:\n",
    "#### $$  P(x,\\lambda)\\;=\\;\\frac{\\lambda^{x}\\;e^{-\\lambda}}{x!}  $$\n",
    "\n",
    "- #### However for the ease of calculation, we have altered the pmf slightly by taking the it as:\n",
    "#### $$  P(x,\\lambda)\\;=\\;\\frac{\\lambda^{x}}{x!}  $$\n",
    "\n",
    "- #### The extra `exponential term` has been added while taking the probability as the input.\n",
    "\n",
    "- #### In the code mentioned below, the functions pertaining to each task has been documented in a well-defined manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Generating the Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initially the range of the values was limited to 34 due to the huge computation overheads and datatype overflow, however changing the way we evaluate the cdf can increase the limit of the function.\n",
    "\"\"\"\n",
    "\n",
    "# Earlier the Upper range of the limit is 171\n",
    "prestored_samples_1a =2000\n",
    "LAMDA_1a= 5\n",
    "size_unif_1a=1200\n",
    "\n",
    "# Generating the cdf of the gaussian distribution\n",
    "CDF_1a =  Poisson_cdf( prestored_samples_1a, LAMDA_1a)* mt.exp(0-LAMDA_1a)\n",
    "\n",
    "# Generating the dataset\n",
    "dataset_Poisson_1a=ITS_poisson( size_unif_1a, prestored_samples_1a, LAMDA_1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1a:float =arr_mean(dataset_Poisson_1a)\n",
    "var_1a:float =arr_variance( dataset_Poisson_1a , mean_1a )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The mean of the dataset is {mean_1a}.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset is {var_1a}.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Visualization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the bin-size\n",
    "BIN_SIZE = [20, 40, 60, 80 ]\n",
    "\n",
    "plt.figure( figsize=(14,14)  ); #plt.rcParams['figure.autolayout']=True\n",
    "for i in range( len( BIN_SIZE ) ):\n",
    "\n",
    "  # Making the condition for the plots and changing their coordinated by the use of subplot function\n",
    "  plt.style.use( 'seaborn-v0_8' )\n",
    "  plt.subplot(2,2,i+1)\n",
    "  plt.title(f\"Bin size={BIN_SIZE[i]}\")\n",
    "  plt.xlabel('Realisation');  plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "  # Showing the bar plot\n",
    "  plt.hist(dataset_Poisson_1a, bins=BIN_SIZE[i], linewidth=1, edgecolor=\"white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Discussion_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The Mean and Variance from the dataset which we have generated from the has come out to be approximately the same as the expectation of the distribution and the variance of the Poisson distribution.\n",
    "- #### This can also be visualized through the bar plot which is made. Most number of values are near to the realisation of mean which is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### It can be inferred from here that if we generate random numbers as a dataset from a distribution then the data generated follows that particular distribution.\n",
    "- #### Additionally, the visualisation for the dataset will also show similar mean and variance to the distribution choosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __B__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Methodology__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The main idea behind the method used is to generate a dataset from uniform distribution which follows Gaussian distribution.\n",
    "\n",
    "- #### This is done with the help of Box-Muller Technique which is defined as follows:\n",
    "  - #### It can be defined as a way to inverse sampling. However, it generates numbers which follow _Standard Normal Distribution_.\n",
    "  - #### The formulas used for the Box-Muller transform are:\n",
    "    $$ Z_1 = R\\;\\cos{(\\theta)}\\;=\\;\\sqrt{-2\\ln{U_1}} \\cos{2\\pi U_2}  $$\n",
    "    $$ Z_2 = R\\;\\sin{(\\theta)}\\;=\\;\\sqrt{-2\\ln{U_2}} \\sin{2\\pi U_1}  $$\n",
    "  - #### Z1 and Z2, generated here, follow standard normal distributions.\n",
    "  - #### The derivation for the Box-Muller technique involves the use of geometry and Pythogoras theorem.\n",
    "\n",
    "- #### Since we have standard normal distributions below which are independent of each other, We convert them to variables which are dependent on each other.\n",
    "  $$  X = \\mu_1 + \\sqrt{ \\sigma_1 }\\;\\;z_1  $$\n",
    "  $$  Y = \\mu_2 + p\\;\\sigma_1\\;z_1 +z_2\\;\\sigma_2\\;\\sqrt{1-p^2}  $$\n",
    "\n",
    "- #### The second variable is transformed such that its dependency on the other variable is taken into account with the help of _Correlation_ and _Overall Covariance_.\n",
    "\n",
    "- #### Finally, the generated dataset is visualized with the help of _Scatterplot_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "num=1000\n",
    "Hmean=65; Wmean=150\n",
    "Hvar=25; Wvar=36\n",
    "corr=1/3\n",
    "Cov=10\n",
    "\n",
    "DATASET_1B=ITS_gaussian(num_samples=num, mean=( Hmean, Wmean), Covariance=[[25,10],[10,36]])\n",
    "\n",
    "x1:np.array=[]; x2:np.array=[]\n",
    "for elm in DATASET_1B:\n",
    "  x1=x1+[elm[0]]\n",
    "  x2=x2+[elm[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1b_height:float =arr_mean(x1)\n",
    "var_1b_height:float =arr_variance( x1 , mean_1b_height )\n",
    "\n",
    "mean_1b_weight:float =arr_mean(x2)\n",
    "var_1b_weight:float =arr_variance( x2 , mean_1b_weight )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The means of the dataset for height and weight are {mean_1b_height} and {mean_1b_weight} respectively.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset for height and weight are {var_1b_height} and {var_1b_weight} respectively.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Visualisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x1, x2, alpha=0.5)\n",
    "\n",
    "plt.title('Scatter plot for Bivariate Gaussian Distribution')\n",
    "plt.xlabel('Height'); plt.ylabel('Weight')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Discussion__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Hence, Box-muller technique can  be used to get a dataset containing points which follow normal distribution.\n",
    "\n",
    "- #### It can be seen that the maximum density of points in the plot is near the mean values of the two variables.\n",
    "\n",
    "- #### We can also see that the density decreases as we go farther from the means of two distribution. This is in conjunction with the normal principle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Results__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### It can be inferred from here that the most number of points from the _Bivariate Normal Distribution_ come from areas which are near the mean values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __C__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Methodology__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The same method is used to get a dataset following Poisson and a bivariate normal distribution as in part _A_ and _B_.\n",
    "\n",
    "- #### The values for the mean and variance can be changed the impact can be seen through the visualisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Poisson_: _Generating the Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initially the range of the values was limited to 34 due to the huge computation overheads and datatype overflow, however changing the way we evaluate the cdf can increase the limit of the function.\n",
    "\"\"\"\n",
    "\n",
    "# Earlier the Upper range of the limit is 171\n",
    "prestored_samples_1c = 2000\n",
    "LAMDA_1c= 10\n",
    "size_unif_1c= 1200\n",
    "\n",
    "# Generating the cdf of the gaussian distribution\n",
    "CDF_1c =  Poisson_cdf( prestored_samples_1c, LAMDA_1c)* mt.exp(0-LAMDA_1c)\n",
    "\n",
    "# Generating the dataset\n",
    "dataset_Poisson_1c=ITS_poisson( num_samples=size_unif_1c, prestored_samples=prestored_samples_1c, lamda=LAMDA_1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1c:float =arr_mean(dataset_Poisson_1c)\n",
    "var_1c:float =arr_variance( dataset_Poisson_1c , mean_1c )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The mean of the dataset is {mean_1c}.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset is {var_1c}.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Gaussian_: _Generating Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "num=1000\n",
    "Temp=30; Sales=100\n",
    "var_temp=16; var_sales=25\n",
    "corr_3c=1/4\n",
    "Cov_3c=5\n",
    "\n",
    "dataset_Gaussian_1c=ITS_gaussian(num_samples=num, mean=( Temp, Sales), Covariance=[[var_temp,Cov_3c],[Cov_3c,var_sales]])\n",
    "\n",
    "x1:np.array=[]; x2:np.array=[]\n",
    "for elm in dataset_Gaussian_1c:\n",
    "  x1=x1+[elm[0]]\n",
    "  x2=x2+[elm[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1c_temp:float =arr_mean(x1)\n",
    "var_1c_temp:float =arr_variance( x1 , mean_1c_temp )\n",
    "\n",
    "mean_1c_sales:float =arr_mean(x2)\n",
    "var_1c_sales:float =arr_variance( x2 , mean_1c_sales )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The means of the dataset for temperature and sales are {mean_1c_temp} and {mean_1c_sales} respectively.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset for temperature and sales are {var_1c_temp} and {var_1c_sales} respectively.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Visualization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the bin-size\n",
    "BIN_SIZE = [30, 60 ]\n",
    "\n",
    "plt.figure( figsize=(14,14)  ); #plt.rcParams['figure.autolayout']=True\n",
    "for i in range( len( BIN_SIZE ) ):\n",
    "\n",
    "  # Making the condition for the plots and changing their coordinated by the use of subplot function\n",
    "  plt.style.use( 'seaborn-v0_8' )\n",
    "  plt.subplot(2,2,i+1)\n",
    "  plt.xlabel('Sales/day');  plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "  # Showing the bar plot\n",
    "  plt.hist(dataset_Poisson_1c, bins=BIN_SIZE[i], linewidth=1, edgecolor=\"white\")\n",
    "  plt.title(f\"Histogram for Poisson distribution [bins={BIN_SIZE[i]}]\")\n",
    "\n",
    "for i in range( len(BIN_SIZE) ):\n",
    "  # Scatter plot\n",
    "  \n",
    "  plt.xlabel('Temperature'); plt.ylabel('Sales on that day')\n",
    "  plt.grid(True)\n",
    "  plt.subplot(2,2,i+3)\n",
    "  plt.scatter(x1, x2, alpha=0.5)\n",
    "  plt.title(f'Scatter plot for Bivariate Gaussian Distribution [bins={BIN_SIZE[i]}]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Discussion__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Through this, we can confirm our earlier hypothesis that the density is highest near the means of the two variables than near other values.\n",
    "\n",
    "- #### Here, we can also see that the means and variance of the sample generated follow the distribution more and more as we increse the size of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Results__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Finally, we can say that the impact on the visualisation with respect to changes in number of samples and the realisation of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Conclusion__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### From the above question, we can say that the major properties of a dataset depends heavily on the distribution from which data has been taken.\n",
    "\n",
    "- ### The number of data points can also cause a huge impact on the overall properties of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# __Question 2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Introduction__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Write a Python code to generate 1000 random numbers from a Poisson distribution with a mean of 3.\n",
    "\n",
    "- ### Transform the generated Poisson numbers to their squares and create a histogram to visualize the distribution of squared values.\n",
    "\n",
    "- ### Now, write a Python code to generate 100 pairs of random numbers from a bivariate Gaussian distribution with means μ1 = 2, μ2 = 3 and covariance matrix Σ = [[1, 0.5], [0.5, 2]].\n",
    "- ### Transform each pair of Gaussian numbers to their squares (both elements of the pair) and create a 3D scatter plot to visualize the distribution of squared values.\n",
    "- ### Compare the histograms from the Poisson distribution and the scatter plot from the multivariate Gaussian distribution in terms of the shape and spread of the squared values.\n",
    "- ### Discuss any insights gained from the visualizations and transformations, considering the characteristics of each distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __A__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Methodology__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The main idea used here is similar to the one used in `Q1.(a)` i.e. to get the cdf of random variable for a large number of realisations of the random variable `X` which follows the Poisson distibution.\n",
    "\n",
    "- #### The Poisson distribution can be represented by the pmf as:\n",
    "#### $$  P(x,\\lambda)\\;=\\;\\frac{\\lambda^{x}\\;e^{\\lambda}}{x!}  $$\n",
    "\n",
    "- #### However for the ease of calculation, we have altered the pmf slightly by taking the it as:\n",
    "#### $$  P(x,\\lambda)\\;=\\;\\frac{\\lambda^{x}}{x!}  $$\n",
    "\n",
    "- #### The extra `exponential term` has been added while taking the probability as the input.\n",
    "\n",
    "- #### In the next part, we have transformed the random variable X to get another random variable Y.\n",
    "#### $$  Y\\;=\\;X^2  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Generating the Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prestored_samples_2a = 2000\n",
    "LAMDA_2a= 3\n",
    "size_unif_2a=1000\n",
    "\n",
    "# Generating the cdf of the gaussian distribution\n",
    "CDF_2a =  Poisson_cdf( prestored_samples_2a, LAMDA_2a)* mt.exp(0-LAMDA_2a)\n",
    "\n",
    "# Generating the dataset\n",
    "dataset_Poisson_2a=ITS_poisson( size_unif_2a, prestored_samples_2a, LAMDA_2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_2a:float =arr_mean(dataset_Poisson_2a)\n",
    "var_2a:float =arr_variance( dataset_Poisson_2a , mean_2a )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The mean of the dataset is {mean_2a}.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset is {var_2a}.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __B__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Transformation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squaring the initial array\n",
    "dataset_Poisson_2a_square=dataset_Poisson_2a**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_2b:float =arr_mean(dataset_Poisson_2a_square)\n",
    "var_2b:float =arr_variance( dataset_Poisson_2a_square , mean_2b )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The mean of the dataset is {mean_2b}.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset is {var_2b}.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Visualization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the bin-size\n",
    "BIN_SIZE = [ 50, 100 ]\n",
    "\n",
    "plt.figure( figsize=(14,14)  ); #plt.rcParams['figure.autolayout']=True\n",
    "for i in range( len( BIN_SIZE ) ):\n",
    "\n",
    "  # Making the condition for the plots and changing their coordinated by the use of subplot function\n",
    "  plt.style.use( 'seaborn-v0_8' )\n",
    "  plt.subplot(2,2,i+1)\n",
    "  plt.title(f\"Bin size={BIN_SIZE[i]}\")\n",
    "\n",
    "  # Showing the bar plot\n",
    "  plt.hist(dataset_Poisson_2a_square, bins=BIN_SIZE[i], linewidth=1, edgecolor=\"white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __C__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Methodology__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The main idea behind the method used is to generate a dataset from uniform distribution which follows Gaussian distribution.\n",
    "\n",
    "- #### This is done with the help of Box-Muller Technique which is defined as follows:\n",
    "  - #### It can be defined as a way to inverse sampling. However, it generates numbers which follow _Standard Normal Distribution_.\n",
    "  - #### The formulas used for the Box-Muller transform are:\n",
    "    $$ Z_1 = R\\;\\cos{(\\theta)}\\;=\\;\\sqrt{-2\\ln{U_1}} \\cos{2\\pi U_2}  $$\n",
    "    $$ Z_2 = R\\;\\sin{(\\theta)}\\;=\\;\\sqrt{-2\\ln{U_2}} \\sin{2\\pi U_1}  $$\n",
    "  - #### Z1 and Z2, generated here, follow standard normal distributions.\n",
    "  - #### The derivation for the Box-Muller technique involves the use of geometry and Pythogoras theorem.\n",
    "\n",
    "- #### Since we have standard normal distributions below which are independent of each other, We convert them to variables which are dependent on each other.\n",
    "  $$  X = \\mu_1 + \\sqrt{ \\sigma_1 }\\;\\;z_1  $$\n",
    "  $$  Y = \\mu_2 + p\\;\\sigma_1\\;z_1 +z_2\\;\\sigma_2\\;\\sqrt{1-p^2}  $$\n",
    "\n",
    "- #### The second variable is transformed such that its dependency on the other variable is taken into account with the help of _Correlation_ and _Overall Covariance_.\n",
    "\n",
    "- #### Then, we transform the variable by squaring their values.\n",
    "\n",
    "- #### Finally, the generated dataset after squaring is visualized with the help of _Scatterplot_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "num=10000\n",
    "P1_mean=2; P2_mean=3\n",
    "P1_var=1; P2_var=2\n",
    "corr=0.5/np.sqrt(P1_var*P1_var)\n",
    "Cov=0.5\n",
    "\n",
    "DATASET_2C=ITS_gaussian(num_samples=num, mean=( P1_mean, P2_mean), Covariance=[[P1_var,Cov],[Cov,P2_var]])\n",
    "\n",
    "x1:np.array=[]; x2:np.array=[]\n",
    "for elm in DATASET_2C:\n",
    "  x1=x1+[elm[0]]\n",
    "  x2=x2+[elm[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_2c_P1:float =arr_mean(x1)\n",
    "var_2c_P1:float =arr_variance( x1 , mean_2c_P1 )\n",
    "\n",
    "mean_2c_P2:float =arr_mean(x2)\n",
    "var_2c_P2:float =arr_variance( x2 , mean_2c_P2 )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The means of the dataset for P1 and P2 are {mean_2c_P1} and {mean_2c_P2} respectively.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset for P1 and P2 are {var_2c_P1} and {var_2c_P2} respectively.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __D__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Transformation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed Variable\n",
    "x1_transformed= np.array( [ elm*elm for elm in x1 ] )\n",
    "x2_transformed= np.array( [ elm*elm for elm in x2 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Displaying the mean and variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_2c_P1_trans:float =arr_mean(x1_transformed)\n",
    "var_2c_P1_trans:float =arr_variance( x1_transformed , mean_2c_P1_trans )\n",
    "\n",
    "mean_2c_P2_trans:float =arr_mean(x2_transformed)\n",
    "var_2c_P2_trans:float =arr_variance( x2_transformed , mean_2c_P2_trans )\n",
    "\n",
    "# Displaying the necessaary information\n",
    "print(f\"The means of the dataset for P1 Squared and P2 Squared are {mean_2c_P1_trans} and {mean_2c_P2_trans} respectively.\",end=\"\\n\\n\")\n",
    "print(f\"The variance of the dataset for P1 Squared and P2 Squared are {var_2c_P1_trans} and {var_2c_P2_trans} respectively.\",end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Visualisation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Scatter plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x1, x2, alpha=0.5)\n",
    "plt.title('Scatter plot for Normal Bivariate Gaussian Distribution')\n",
    "plt.xlabel('P1'); plt.ylabel('P2')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x1_transformed, x2_transformed, alpha=0.5)  \n",
    "plt.title('Scatter plot for Transformed Bivariate Gaussian Distribution')\n",
    "plt.xlabel('P1'); plt.ylabel('P2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zr=np.ones(len(x1_transformed))\n",
    "# \n",
    "# ax=plt.axes(projection=\"3d\")\n",
    "# ax.scatter3D(x1_transformed, x2_transformed , zr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __E__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The Histogram which we obtained from the Poisson distribution shows the maximum values nearly equal to 3 and 9 respectively which shows that by squaring values which follow Poisson distribution, we get a similar -to poisson distribution whose mean is lies around the square of previous mean.\n",
    "\n",
    "- #### We can also see here that the distribution has some differences which can be seen said due to the size of the samples.\n",
    "\n",
    "- #### The spread also increases when we sqaure the values which follow the Poisson distribution.\n",
    "\n",
    "- #### The similar trend can be seen in the case of Scatterplot obtained from the Normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __F__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The major insight which can be gained from the above analysis is that the size of the sample matters a lot when generating numbers which follow a specific distribution.\n",
    "\n",
    "- #### Another important point to note here is that the mean and variance of the sample see a similar trend in their distribution and if we apply a transformation on the values, this can also be seen in the visualisation.\n",
    "\n",
    "- ### The shape of the distribution does not sees a drastic change with the change in sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# __References__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### [_Numpy Documentation_](https://numpy.org/devdocs/user/absolute_beginners.html)\n",
    "- #### [Help in Markdown](https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index)\n",
    "- #### [Box-Muller Technique](https://www.statisticshowto.com/box-muller-transform-simple-definition/)\n",
    "- #### [Matplotlib : Documentation](https://matplotlib.org/stable/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
