{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### We have calculated the least square estimators for $ \\alpha \\; and \\; \\beta $ which are A and B respectively by using the formula as follows:\n",
    "  #### $$ B \\; = \\; \\frac{\\sum{} x_i Y_i - n\\bar{x}\\bar{Y}}{\\sum{(x_i)^2} - n\\bar{x}^2} $$\n",
    "  #### $$ A \\; = \\; \\bar{Y} - B\\bar{x} $$\n",
    "\n",
    "- ### The Regression line is interpreted using these A and B as intercept and slope respectively.\n",
    "\n",
    "- ### Prediction of Moisture Content is done through equation obtained using the regression line.\n",
    "\n",
    "- ### The Goodness of fit can be easily assesed with the help of a measuring parameter like Mean Squared Error(MSE).\n",
    "\n",
    "- ### Confidence interval can be assesed by predicting a range for the given value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_least_squares_estimator(x: np.array, y: np.array)->tuple:\n",
    "  \"\"\"_Summary_\n",
    "    This returns the least squares estimator for the given samples of x and y.\n",
    "  Args:\n",
    "      x (np.array): This is the numpy array which contains the sample for the relative humidity level.\n",
    "      y (np.array): This is the numpy array which contains the sample for the moisture content.\n",
    "  \"\"\"\n",
    "  n= len(x)\n",
    "  B:float = ( np.sum(x*y) - (np.sum(x)*np.sum(y))/n )/ (np.sum(x**2)- (n * ( (np.sum(x)/n)**2) ))\n",
    "  A:float = np.sum(y)/n - B*np.sum(x)/n\n",
    "\n",
    "  return (round(A,2), round(B,2) ); \n",
    "\n",
    "def interpret_regression_line(slope:float, intercept:float)->None:\n",
    "  \"\"\"_summary_\n",
    "      This interprets the regression line by explaining the slope and the intercept.\n",
    "  Args:\n",
    "      slope (float): This is the slope which is calculated as least square estimator.\n",
    "      intercept (float): This is the intercept obtained from the least Sqaure Estimator.\n",
    "  \"\"\"\n",
    "  print(f\"We have taken the least square estimator to get the values of slope and intercept.\\nSlope: {slope}, Intercept: {intercept}\\nThe significance is that the slope and intercept calculated from Least Sqaure Estimator are unbiased estimator of A and B.\", end=\"\\n\\n\")\n",
    "  \n",
    "def predict_moisture_content(slope:float, intercept:float, x:np.array):\n",
    "  \"\"\"_summary_\n",
    "    This helps in predicting the moisture content level with the help of arguments provided.\n",
    "  Args:\n",
    "      slope (float): _description_\n",
    "      intercept (float): _description_\n",
    "      humidity (np.array): _description_\n",
    "  \"\"\"\n",
    "  y_pr= intercept + slope*x\n",
    "  return y_pr\n",
    "\n",
    "def plot_regression_line(slope:float, intercept:float, X:np.array, Y:np.array ):\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      slope (float): _description_\n",
    "      intercept (float): _description_\n",
    "      x (np.array): _description_\n",
    "      y (np.array): _description_\n",
    "  \"\"\"\n",
    "  X_data= np.array( [ 0.08* i for i in range(1000)] )\n",
    "  Y_data= X_data*slope + intercept\n",
    "\n",
    "  plt.figure( figsize=(10,8) )\n",
    "  plt.style.use('seaborn-v0_8')\n",
    "  plt.title(\"Regression line vs actual data\")\n",
    "  plt.xlabel('Relative Humidity'); plt.ylabel('Moisture Content')\n",
    "\n",
    "  # Plotting the scatterplot values\n",
    "  plt.scatter(X,Y, linewidths=2, edgecolors='black' )\n",
    "  plt.scatter(X_data, Y_data, linewidths=10e-9, edgecolors='red', marker=\".\")\n",
    "  plt.show()\n",
    "\n",
    "def assess_goodness_of_fit(y:np.array, y_predict:np.array):\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      y (np.array): This is the original moisture content level given in the question. \n",
    "      y_predict (np.array): This is the predicted moisture content level given in the question.\n",
    "  \"\"\"\n",
    "  ans:float= sum( (y_predict-y)**2 )\n",
    "  return round(ans, 2), round( ans/len(y), 2)\n",
    "\n",
    "def compute_confidence_interval(humidity, size, mean, SSE, Sxx, slope, intercept  ):\n",
    "  \"\"\"_summary_\n",
    "  \"\"\"\n",
    "  range_:float = np.sqrt( ( ((1+size)/size) + ((humidity-mean)**2)/Sxx) * (SSE/(size-2)))\n",
    "  t_val= stats.t.ppf(.975, size-2)\n",
    "  org_val= slope*humidity + intercept\n",
    "\n",
    "  print(f\"The range is between {round(org_val - range_*t_val,2)} and {round(org_val + range_*t_val, 2)} with 95% confidence interval\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Humidity= np.array( [46, 53, 29, 61, 36, 39, 47, 49, 52, 38, 55, 32, 57, 54, 44] )\n",
    "Moisture_org= np.array( [12, 15, 7, 17, 10, 11, 11, 12, 14, 9, 16, 8, 18, 14, 12] )\n",
    "\n",
    "intercept, slope= calculate_least_squares_estimator(x=Humidity, y=Moisture_org )\n",
    "print(f\"The Slope and the Variance of the regression line are {intercept} and {slope} respectively.\", end=\"\\n\\n\")\n",
    "interpret_regression_line( slope, intercept )\n",
    "\n",
    "Moisture_predict= predict_moisture_content(slope=slope, intercept=intercept, x=Humidity)\n",
    "print(f\"The predicted Moisture for the Humidity is:\\n{Moisture_predict}\", end=\"\\n\\n\")\n",
    "\n",
    "print(f\"The plot of the regression line and the actual data provided is given as follows:\")\n",
    "plot_regression_line(slope, intercept, Humidity, Moisture_org)\n",
    "\n",
    "SSE, MSE= assess_goodness_of_fit( Moisture_org, Moisture_predict )\n",
    "print(f\"The Sum of Squared Error is {SSE} and the Mean of Sqaured Error is {MSE}. The smaller the values of SSE and MSE, the better the line fits.\",end=\"\\n\\n\")\n",
    "\n",
    "mean1= np.sum( Humidity )/10\n",
    "Sxx= np.sum( np.array( [ (val-mean1)**2  for val in Humidity] ) )\n",
    "print(mean1)\n",
    "Sample1= 25\n",
    "compute_confidence_interval(Sample1, 10, mean1, SSE, Sxx, slope, intercept )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### We can see above that not all data points align with the regression line. This is again due to the residual which is present. This can also be pertained to the irreducable error.\n",
    "\n",
    "- #### The range for the 95% confidence interval choosen also matches with the values of the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### We have calculated the least square estimators for $ \\alpha \\; and \\; \\beta $ which are A and B respectively by using the formula as follows:\n",
    "  ##### $$ B \\; = \\; \\frac{\\sum{} x_i Y_i - n\\bar{x}\\bar{Y}}{\\sum{(x_i)^2} - n\\bar{x}^2} $$\n",
    "\n",
    "- #### Prediction of Score is done through equation obtained by using the time of study, slope and intercept.\n",
    "\n",
    "- #### During the Hypothesis testing, we take the following hypothesis:\n",
    "  ##### $$ H_0: \\beta=0 \\; \\; H_1: \\beta>0 $$\n",
    "\n",
    "- #### The Hypothesis $ H_0 $ point out that the Score in Exam is completely independent of the number of hours put in study.\n",
    "- #### Initutively, This is not the case. We will prove this by Hypothesis and rejecting the Null Hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slope_intercept( x: np.array, y: np.array )->tuple:\n",
    "\n",
    "  n= len(x)\n",
    "  B:float = ( np.sum(x*y) - (np.sum(x)*np.sum(y))/n )/ (np.sum(x**2)- (n * ( (np.sum(x)/n)**2) ))\n",
    "  A:float = np.sum(y)/n - B*np.sum(x)/n\n",
    "\n",
    "  return ( round(A,2), round(B,2) ); \n",
    "\n",
    "def vis_relationship( X:np.array, Y:np.array, slope, intercept ):\n",
    "\n",
    "  X_data= np.array( [ 0.08* i for i in range(400)] )\n",
    "  Y_data= X_data*slope + intercept\n",
    "\n",
    "  plt.figure( figsize=(10,8) )\n",
    "  plt.style.use('seaborn-v0_8')\n",
    "  plt.title(\"Actual data plotted\")\n",
    "  plt.xlabel('Time'); plt.ylabel('Score')\n",
    "\n",
    "  # Plotting the scatterplot values\n",
    "  plt.scatter(X,Y, linewidths=2, edgecolors='black' )\n",
    "  plt.scatter(X_data, Y_data, linewidths=10e-9, edgecolors='red', marker=\".\")\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def predict_exam_score( Time:float, slope:float, intercept:float )->float:\n",
    "  \n",
    "  Score= Time*slope + intercept\n",
    "  return Score\n",
    "\n",
    "def plot_residual(Time, Score, slope, intercept):\n",
    "  \n",
    "  residual= Score - ( Time*slope + intercept )\n",
    "\n",
    "\n",
    "  plt.figure(figsize=(10,8))\n",
    "  plt.style.use( 'seaborn-v0_8' )\n",
    "  plt.xlabel('Study Time'); plt.ylabel('Residual')\n",
    "  plt.scatter(x=Time, y=residual )\n",
    "\n",
    "  return residual\n",
    "\n",
    "def hypothesis_test(slope, size, Sxx, SSE):\n",
    "  \n",
    "  coeff= np.sqrt( (size-2)* Sxx/SSE)\n",
    "  test_stat= slope * coeff\n",
    "  t_stat= stats.t.ppf( 0.975, size-2 )\n",
    "\n",
    "  return round(test_stat, 2), round(t_stat, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time= np.array( [ 2 ,4 ,6 ,8 ,10 ,12 ,14 ,16 ,18 ,20 ,22 ,24 ,26 ,28 ,30 ] )\n",
    "Score= np.array( [ 70, 75, 80, 85, 90, 92, 94, 96, 98, 100, 101, 102, 103, 104, 105 ] )\n",
    "\n",
    "intercept2, slope2= calculate_slope_intercept(x=Time, y=Score )\n",
    "print(f\"The Slope and the Variance of the regression line are {intercept} and {slope} respectively.\", end=\"\\n\\n\")\n",
    "\n",
    "vis_relationship(X= Time, Y= Score, slope=slope2, intercept=intercept2)\n",
    "\n",
    "sample_value= 23\n",
    "predicted_score= predict_exam_score(Time= sample_value, slope=slope2, intercept= intercept2)\n",
    "print(f\"The Predicted score for the study time of {sample_value} is {predicted_score}.\", end=\"\\n\\n\")\n",
    "\n",
    "Residuals= plot_residual(Time, Score, slope2, intercept2)\n",
    "print(f\"We can see from the above graph that the distribution of the residuals first increases and then decreases. This could lead us to the hypothesis that Studying for less hours or too much greater hours does not lead to a well-defined distribution of marks.\",end=\"\\n\\n\")\n",
    "\n",
    "test_stat, t_stat= hypothesis_test(slope2, 10, Sxx, SSE)\n",
    "print(f\"The Test-Statistic and the t-Statistic have come out to be {test_stat} and {t_stat}. As We can see that the test Statistic is greater than the t-statistic, We can reject the hypothesis that β=0 i.e. the Test score are completely independent of the hours studied for the test.\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### The Scatter plot with the Study time vs Residual describes a curve which first increase and then decreases.\n",
    "\n",
    "- #### We can see from the above graph that the distribution of the residuals first increases and then decreases. \n",
    "\n",
    "- #### This could lead us to the hypothesis that Studying for less hours or too much greater hours does not lead to a well-defined distribution of marks. Through this, we reject the Null Hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
