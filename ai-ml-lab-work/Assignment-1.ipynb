{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELSclFBlADr2"
   },
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Aa-nRCzPVdF"
   },
   "source": [
    "I have created a multilingual text translation using IndicTrans2 models which was originally trained with the fairseq to HuggingFace transformers.\n",
    "\n",
    "## Procedure\n",
    "  1. There are 3 cases of translation:\n",
    "    \n",
    "| Language                       | Code      |   | Language                        | Code      |\n",
    "|---|---|---|---|---|\n",
    "Bengali | ben_Beng  | to | Punjabi  | pan_Guru  |\n",
    "Marathi | mar_Deva | to | Gujarati | guj_Gujr  |\n",
    "Kannada | kan_Knda  | to | Sanskrit  | san_Deva  |\n",
    "\n",
    "  2. For checking the validity of the translation, The Sentence taken are taken in English and then converted to each of the languages.\n",
    "  3. After that, translation is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cfsv02IeP2It"
   },
   "source": [
    "## Necessary Step\n",
    "\n",
    "Please run the cells below to install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKcYlUZYGLrt"
   },
   "outputs": [],
   "source": [
    "# Clone the required Git repository for IndicTrans2\n",
    "%%capture\n",
    "!git clone https://github.com/AI4Bharat/IndicTrans2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3vs7FkIGSxK"
   },
   "outputs": [],
   "source": [
    "# Clone the Hugging face interface from github\n",
    "%%capture\n",
    "%cd /content/IndicTrans2/huggingface_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddkRAXQ2Git0"
   },
   "outputs": [],
   "source": [
    "# Install other essential dependecies for working of the transformer\n",
    "%%capture\n",
    "!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n",
    "!python3 -c \"import nltk; nltk.download('punkt')\"\n",
    "!python3 -m pip install bitsandbytes scipy accelerate datasets\n",
    "!python3 -m pip install sentencepiece\n",
    "\n",
    "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
    "%cd IndicTransTokenizer\n",
    "!python3 -m pip install --editable ./\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjN7ub1tO33H"
   },
   "source": [
    "Restart your run-time first and then run the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SLBIw6rQB-0"
   },
   "source": [
    "## Working for Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNM92xDow72u"
   },
   "source": [
    "1. Importing the important modules:\n",
    "  * transformer\n",
    "  * torch\n",
    "  * AutoModelForSeq2SeqLM from transformer\n",
    "  * BitsAndBytesConfig from transformer\n",
    "  * IndicProcessor from from IndicTransTokenizer\n",
    "  * IndicTransTokenizer from IndicTransTokenizer\n",
    "\n",
    "2. Set the Batch size equal to 4. Then create a variable DEVICE and set it to \"cuda\" if torch.cuda.is_available() or else set it as \"cpu\". Finally set Quantization as \"None\"\n",
    "\n",
    "3. Two functions are there.\n",
    "    * First function to intialise the model and the tokenizer and returns both\n",
    "    * Another function which helps in the translation of a whole batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRfv0xszaQfx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n",
    "import transformers as trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYczM2U6G1Zv"
   },
   "outputs": [],
   "source": [
    "# Set the variables\n",
    "BATCH_SIZE= 4;\n",
    "DEVICE= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "Quantization= None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLnr2RfM0QTt"
   },
   "source": [
    "### Model initializer and tokenizer function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIC98HYa0XRN"
   },
   "source": [
    "Create a function initialize_model_and_tokenizer which takes in 3 arguments: ckpt_dir, direction, quantization.\n",
    "Inside the function, if quantization  = '4-bit' then create a variable qconfig and use appropriate BitsAndByteConfig to instantiate it. Else if quantization  = '8-bit', then do the necessary. Else, set it to None.\n",
    "\n",
    "BitsAndBytesConfig(https://huggingface.co/docs/transformers/en/main_classes/quantization#transformers.BitsAndBytesConfig).)\n",
    "\n",
    "Next, create a variable tokenizer\n",
    "\n",
    "Next step will be to create a model variable set to AutoModelForSeq2SeqLM where we have to load the pretrained model from checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xj1WCNjuHG-d"
   },
   "outputs": [],
   "source": [
    "# Create a function initialize_model_and_tokenizer which takes in 4 arguments: ckpt_dir, direction, quantization.\n",
    "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
    "    if (quantization  == '4-bit'):\n",
    "      qconfig= BitsAndBytesConfig(\n",
    "          load_in_4bit=True,\n",
    "          bnb_4bit_use_double_quant= True,\n",
    "          bnb_4bit_compute_dtype= torch.bfloat16\n",
    "    )\n",
    "    elif (quantization  == '8-bit'):\n",
    "      qconfig= BitsAndBytesConfig(\n",
    "          load_in_8bit=True,\n",
    "          bnb_8bit_use_double_quant= True,\n",
    "          bnb_8bit_compute_dtype= torch.bfloat32\n",
    "    )\n",
    "    else:\n",
    "      qconfig=None\n",
    "\n",
    "    # Create a variable tokenizer and set it as IndicTransTokenizer with direction set as direction.\n",
    "    tokenizer= IndicTransTokenizer( direction=direction )\n",
    "\n",
    "    # Create a model variable set to AutoModelForSeq2SeqLM, Keep trust_remote_code=True, low_cpu_mem_usage=True and quantization_config=qconfig.\n",
    "    model= AutoModelForSeq2SeqLM.from_pretrained(ckpt_dir, trust_remote_code=True, low_cpu_mem_usage=True, quantization_config=qconfig)\n",
    "\n",
    "\n",
    "    # if qconfig is none, save the model in device.\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        if DEVICE == \"cuda\":\n",
    "            model.half()\n",
    "\n",
    "    model.eval();\n",
    "    # return both tokenizer and model\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCWrirPAF3aM"
   },
   "source": [
    "## Helper Function to get translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPlUvJN1CX0K"
   },
   "outputs": [],
   "source": [
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
    "    translations = []\n",
    "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            src=True,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Generate translations using the model\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decode the generated tokens into text\n",
    "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
    "\n",
    "        # Postprocess the translations, including entity replacement\n",
    "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsosjO0PJJsU"
   },
   "source": [
    "## Languages and their codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X644TodGGkBE"
   },
   "source": [
    "Now we have to Finally join all the functions and datasets together to create our own predictions.\n",
    "\n",
    "Here is the list of languages supported by the IndicTrans2 models:\n",
    "\n",
    "| Language                       | Code      | Language                        | Code      | Language                       | Code      |\n",
    "|--------------------------------|-----------|---------------------------------|-----------|--------------------------------|-----------|\n",
    "| Assamese                       | asm_Beng  | Kashmiri (Arabic)               | kas_Arab  | Punjabi                        | pan_Guru  |\n",
    "| Bengali                        | ben_Beng  | Kashmiri (Devanagari)           | kas_Deva  | Sanskrit                       | san_Deva  |\n",
    "| Bodo                           | brx_Deva  | Maithili                        | mai_Deva  | Santali                        | sat_Olck  |\n",
    "| Dogri                          | doi_Deva  | Malayalam                       | mal_Mlym  | Sindhi (Arabic)                | snd_Arab  |\n",
    "| English                        | eng_Latn  | Marathi                         | mar_Deva  | Sindhi (Devanagari)            | snd_Deva  |\n",
    "| Konkani                        | gom_Deva  | Manipuri (Bengali)              | mni_Beng  | Tamil                          | tam_Taml  |\n",
    "| Gujarati                       | guj_Gujr  | Manipuri (Meitei)               | mni_Mtei  | Telugu                         | tel_Telu  |\n",
    "| Hindi                          | hin_Deva  | Nepali                          | npi_Deva  | Urdu                           | urd_Arab  |\n",
    "| Kannada                        | kan_Knda  | Odia                            | ory_Orya  |                                |           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH-mfoBa_WPM"
   },
   "source": [
    "## Input Lines in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtGev7pW8T06"
   },
   "outputs": [],
   "source": [
    "lan_en=[\n",
    "    \"When I was young, I used to go to the park every day.\",\n",
    "    \"He has many old books, which he inherited from his ancestors.\",\n",
    "    \"I can't figure out how to solve my problem.\",\n",
    "    \"She is very hardworking and intelligent, which is why she got all the good marks.\",\n",
    "    \"We watched a new movie last week, which was very inspiring.\",\n",
    "    \"If you had met me at that time, we would have gone out to eat.\",\n",
    "    \"She went to the market with her sister to buy a new sari.\",\n",
    "    \"Raj told me that he is going to his grandmother's house next month.\",\n",
    "    \"All the kids were having fun at the party and were eating lots of sweets.\",\n",
    "    \"My friend has invited me to his birthday party, and I will give him a gift.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrqfdTQBDxWR"
   },
   "source": [
    "## Bengali to Punjabi Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VheCBqzhMV9Z",
    "outputId": "2085165f-130c-4b54-fca6-110077b4e50b"
   },
   "outputs": [],
   "source": [
    "input_bengali=[\n",
    " 'আমি যখন ছোট ছিলাম, আমি প্রতিদিন পার্কে যেতাম।',\n",
    " 'তাঁর কাছে অনেক পুরনো বই রয়েছে, যা তিনি তাঁর পূর্বপুরুষদের কাছ থেকে উত্তরাধিকার সূত্রে পেয়েছিলেন।',\n",
    " 'আমি বুঝতে পারি না কিভাবে আমার সমস্যার সমাধান করব।',\n",
    " 'সে খুব পরিশ্রমী এবং বুদ্ধিমান, যে কারণে সে সমস্ত ভাল নম্বর পেয়েছে।',\n",
    " 'আমরা গত সপ্তাহে একটি নতুন সিনেমা দেখেছি, যা খুব অনুপ্রেরণামূলক ছিল।',\n",
    " 'আপনি যদি সেই সময় আমার সঙ্গে দেখা করতেন, তাহলে আমরা বাইরে খেতে যেতাম।',\n",
    " 'সে তার বোনের সাথে একটি নতুন শাড়ি কিনতে বাজারে গিয়েছিল।',\n",
    " 'রাজ আমাকে বলেছিল যে সে আগামী মাসে তার দাদির বাড়িতে যাচ্ছে।',\n",
    " 'সব বাচ্চারা পার্টিতে মজা করছিল এবং প্রচুর মিষ্টি খাচ্ছিল।',\n",
    " 'আমার বন্ধু আমাকে তার জন্মদিনের পার্টিতে আমন্ত্রণ জানিয়েছে এবং আমি তাকে একটি উপহার দেব।'\n",
    " ]\n",
    "\n",
    "output_punjabi=[\n",
    " 'ਜਦੋਂ ਮੈਂ ਛੋਟਾ ਸੀ, ਮੈਂ ਹਰ ਰੋਜ਼ ਪਾਰਕ ਜਾਂਦਾ ਸੀ।',\n",
    " 'ਉਨ੍ਹਾਂ ਕੋਲ ਬਹੁਤ ਸਾਰੀਆਂ ਪੁਰਾਣੀਆਂ ਕਿਤਾਬਾਂ ਹਨ, ਜੋ ਉਨ੍ਹਾਂ ਨੂੰ ਆਪਣੇ ਪੁਰਖਿਆਂ ਤੋਂ ਵਿਰਾਸਤ ਵਿੱਚ ਮਿਲੀਆਂ ਹਨ।',\n",
    " 'ਮੈਨੂੰ ਸਮਝ ਨਹੀਂ ਆ ਰਿਹਾ ਕਿ ਮੈਂ ਆਪਣੀ ਸਮੱਸਿਆ ਦਾ ਹੱਲ ਕਿਵੇਂ ਕਰਾਂ।',\n",
    " 'ਉਹ ਬਹੁਤ ਮਿਹਨਤੀ ਅਤੇ ਬੁੱਧੀਮਾਨ ਹੈ, ਇਸੇ ਲਈ ਉਸ ਨੂੰ ਸਾਰੇ ਚੰਗੇ ਅੰਕ ਮਿਲੇ।',\n",
    " 'ਅਸੀਂ ਪਿਛਲੇ ਹਫ਼ਤੇ ਇੱਕ ਨਵੀਂ ਫਿਲਮ ਵੇਖੀ, ਜੋ ਬਹੁਤ ਪ੍ਰੇਰਣਾਦਾਇਕ ਸੀ।',\n",
    " 'ਜੇ ਤੁਸੀਂ ਉਸ ਸਮੇਂ ਮੈਨੂੰ ਮਿਲਦੇ ਤਾਂ ਅਸੀਂ ਖਾਣਾ ਖਾਣ ਲਈ ਬਾਹਰ ਜਾਂਦੇ।',\n",
    " 'ਉਹ ਆਪਣੀ ਭੈਣ ਨਾਲ ਨਵੀਂ ਸਾਡ਼ੀ ਖਰੀਦਣ ਲਈ ਬਾਜ਼ਾਰ ਗਈ ਸੀ।',\n",
    " 'ਰਾਜ ਨੇ ਮੈਨੂੰ ਦੱਸਿਆ ਕਿ ਉਹ ਅਗਲੇ ਮਹੀਨੇ ਆਪਣੀ ਦਾਦੀ ਦੇ ਘਰ ਜਾ ਰਿਹਾ ਹੈ।',\n",
    " 'ਸਾਰੇ ਬੱਚੇ ਪਾਰਟੀ ਵਿੱਚ ਬਹੁਤ ਮਸਤੀ ਕਰ ਰਹੇ ਸਨ ਅਤੇ ਬਹੁਤ ਸਾਰੀਆਂ ਮਠਿਆਈਆਂ ਖਾ ਰਹੇ ਸਨ।',\n",
    " 'ਮੇਰੇ ਦੋਸਤ ਨੇ ਮੈਨੂੰ ਆਪਣੇ ਜਨਮਦਿਨ ਦੀ ਪਾਰਟੀ ਵਿੱਚ ਸੱਦਾ ਦਿੱਤਾ ਹੈ, ਅਤੇ ਮੈਂ ਉਸਨੂੰ ਇੱਕ ਤੋਹਫ਼ਾ ਦੇਵਾਂਗਾ।'\n",
    " ]\n",
    "\n",
    "AI4_BHARAT= \"ai4bharat/indictrans2-indic-indic-1B\"; my_direction=\"/content/IndicTrans2/huggingface_interface/IndicTransTokenizer/IndicTransTokenizer/indic-indic/\";\n",
    "\n",
    "# getting tokenizer and model by passing arg. to initialize_model_and_tokenizer function\n",
    "Tokenizer, model= initialize_model_and_tokenizer( ckpt_dir=AI4_BHARAT, direction= my_direction, quantization=\"4-bit\"  )\n",
    "\n",
    "indic= IndicProcessor(inference=True)\n",
    "\n",
    "# Choose the source langauge as English and target language as Hindi.\n",
    "lan_src_1= \"ben_Beng\";  lan_tar_1=\"pan_Guru\"\n",
    "\n",
    "# Find target translation using the batch_translate function with arg: input_sentences, src_lang, tgt_lang, model, tokenizer, ip\n",
    "target_trans_1= batch_translate( input_bengali, lan_src_1, lan_tar_1, model, Tokenizer, indic  )\n",
    "\n",
    "del Tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eStq2aoBMWfo",
    "outputId": "59abe190-cea7-487f-98ef-1d78edc90ebf"
   },
   "outputs": [],
   "source": [
    "target_trans_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiMcGBvPD5qN"
   },
   "source": [
    "## Marathi to Gujrati conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x86sXfN6EEx_",
    "outputId": "2a6941fb-07f8-43fc-ae37-0b7b82cfa340"
   },
   "outputs": [],
   "source": [
    "input_marathi= [\n",
    " 'मी लहान असताना दररोज उद्यानात जायचो.',\n",
    " 'त्याच्याकडे अनेक जुनी पुस्तके आहेत, जी त्याला त्याच्या पूर्वजांकडून वारशाने मिळाली आहेत.',\n",
    " 'माझ्या समस्येचे निराकरण कसे करावे हे मला समजत नाही.',\n",
    " 'ती खूप मेहनती आणि बुद्धिमान आहे, म्हणूनच तिला सर्व चांगले गुण मिळाले.',\n",
    " 'आम्ही गेल्या आठवड्यात एक नवीन चित्रपट पाहिला, जो खूप प्रेरणादायी होता.',\n",
    " 'त्यावेळी तुम्ही मला भेटला असता तर आम्ही बाहेर जेवायला गेलो असतो.',\n",
    " 'ती तिच्या बहिणीसोबत नवीन साडी खरेदी करण्यासाठी बाजारात गेली.',\n",
    " 'राजने मला सांगितले की तो पुढच्या महिन्यात त्याच्या आजीच्या घरी जात आहे.',\n",
    " 'सर्व मुले पार्टीमध्ये मजा करत होती आणि भरपूर मिठाई खात होती.',\n",
    " 'माझ्या मित्राने मला त्याच्या वाढदिवसाच्या सोहळ्याला आमंत्रित केले आहे आणि मी त्याला भेटवस्तू देईन.'\n",
    "]\n",
    "output_gujrati= [\n",
    " 'જ્યારે હું નાનો હતો, ત્યારે હું દરરોજ બગીચામાં જતો હતો.',\n",
    " 'તેમની પાસે ઘણા જૂના પુસ્તકો છે, જે તેમને તેમના પૂર્વજો પાસેથી વારસામાં મળ્યા હતા.',\n",
    " 'હું સમજી શકતો નથી કે મારી સમસ્યાનો ઉકેલ કેવી રીતે લાવવો.',\n",
    " 'તે ખૂબ જ મહેનતુ અને બુદ્ધિશાળી છે, તેથી જ તેને બધા સારા ગુણ મળ્યા.',\n",
    " 'અમે ગયા અઠવાડિયે એક નવી ફિલ્મ જોઈ, જે ખૂબ જ પ્રેરણાદાયક હતી.',\n",
    " 'જો તમે તે સમયે મને મળ્યા હોત તો અમે બહાર જમવા ગયા હોત.',\n",
    " 'તે તેની બહેન સાથે નવી સાડી ખરીદવા માટે બજારમાં ગઈ હતી.',\n",
    " 'રાજે મને કહ્યું કે તે આવતા મહિને તેની દાદીના ઘરે જઈ રહ્યો છે.',\n",
    " 'બધા બાળકો પાર્ટીમાં મજા કરી રહ્યા હતા અને ઘણી બધી મીઠાઈઓ ખાઈ રહ્યા હતા.',\n",
    " 'મારા મિત્રે મને તેના જન્મદિવસની પાર્ટીમાં આમંત્રણ આપ્યું છે, અને હું તેને ભેટ આપીશ.'\n",
    " ]\n",
    "\n",
    "AI4_BHARAT= \"ai4bharat/indictrans2-indic-indic-1B\"; my_direction=\"/content/IndicTrans2/huggingface_interface/IndicTransTokenizer/IndicTransTokenizer/indic-indic/\";\n",
    "\n",
    "# getting tokenizer and model by passing arg. to initialize_model_and_tokenizer function\n",
    "Tokenizer, model= initialize_model_and_tokenizer( ckpt_dir=AI4_BHARAT, direction= my_direction, quantization=\"4-bit\"  )\n",
    "\n",
    "indic= IndicProcessor(inference=True)\n",
    "\n",
    "# Choose the source langauge as English and target language as Hindi.\n",
    "lan_src_2= \"mar_Dev\"; lan_tar_2=\"guj_Gujr\"\n",
    "\n",
    "# Find target translation using the batch_translate function with arguments: input_sentences, src_lang, tgt_lang, model, tokenizer, ip\n",
    "target_trans_2= batch_translate(input_marathi , lan_src_2, lan_tar_2, model, Tokenizer, indic  )\n",
    "\n",
    "del Tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhD2Va8_EDsf",
    "outputId": "4b0908fe-27c8-466f-a17d-fd192da11fce"
   },
   "outputs": [],
   "source": [
    "target_trans_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgd8TFDHIsoa"
   },
   "source": [
    "## Kannada to Sanskrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhDPnxdgMW2K",
    "outputId": "695a11f6-ddd5-4a05-ef7d-b48cd3242cca"
   },
   "outputs": [],
   "source": [
    "input_kannada= [\n",
    " 'ನಾನು ಚಿಕ್ಕವಳಿದ್ದಾಗ, ಪ್ರತಿದಿನ ಉದ್ಯಾನವನಕ್ಕೆ ಹೋಗುತ್ತಿದ್ದೆ.',\n",
    " 'ಅವರು ತಮ್ಮ ಪೂರ್ವಜರಿಂದ ಆನುವಂಶಿಕವಾಗಿ ಪಡೆದ ಅನೇಕ ಹಳೆಯ ಪುಸ್ತಕಗಳನ್ನು ಹೊಂದಿದ್ದಾರೆ.',\n",
    " 'ನನ್ನ ಸಮಸ್ಯೆಯನ್ನು ಹೇಗೆ ಪರಿಹರಿಸಿಕೊಳ್ಳುವುದು ಎಂದು ನನಗೆ ಅರ್ಥವಾಗುತ್ತಿಲ್ಲ.',\n",
    " 'ಅವಳು ತುಂಬಾ ಕಷ್ಟಪಟ್ಟು ದುಡಿಯುವವಳು ಮತ್ತು ಬುದ್ಧಿವಂತಳು, ಅದಕ್ಕಾಗಿಯೇ ಅವಳು ಎಲ್ಲಾ ಉತ್ತಮ ಅಂಕಗಳನ್ನು ಪಡೆದಳು.',\n",
    " 'ನಾವು ಕಳೆದ ವಾರ ಹೊಸ ಚಲನಚಿತ್ರವೊಂದನ್ನು ನೋಡಿದೆವು, ಅದು ಬಹಳ ಸ್ಪೂರ್ತಿದಾಯಕವಾಗಿತ್ತು.',\n",
    " 'ಆ ಸಮಯದಲ್ಲಿ ನೀವು ನನ್ನನ್ನು ಭೇಟಿಯಾಗಿದ್ದರೆ, ನಾವು ತಿನ್ನಲು ಹೊರಗೆ ಹೋಗುತ್ತಿದ್ದೆವು.',\n",
    " 'ಆಕೆ ತನ್ನ ಸಹೋದರಿಯೊಂದಿಗೆ ಹೊಸ ಸೀರೆಯನ್ನು ಖರೀದಿಸಲು ಮಾರುಕಟ್ಟೆಗೆ ಹೋದಳು.',\n",
    " 'ಮುಂದಿನ ತಿಂಗಳು ತನ್ನ ಅಜ್ಜಿಯ ಮನೆಗೆ ಹೋಗುತ್ತಿದ್ದೇನೆ ಎಂದು ರಾಜ್ ನನಗೆ ಹೇಳಿದನು.',\n",
    " 'ಎಲ್ಲಾ ಮಕ್ಕಳು ಪಾರ್ಟಿಯಲ್ಲಿ ಮೋಜು ಮಾಡುತ್ತಿದ್ದರು ಮತ್ತು ಸಾಕಷ್ಟು ಸಿಹಿತಿಂಡಿಗಳನ್ನು ತಿನ್ನುತ್ತಿದ್ದರು.',\n",
    " 'ನನ್ನ ಸ್ನೇಹಿತ ತನ್ನ ಹುಟ್ಟುಹಬ್ಬದ ಸಂತೋಷಕೂಟಕ್ಕೆ ನನ್ನನ್ನು ಆಹ್ವಾನಿಸಿದ್ದಾನೆ ಮತ್ತು ನಾನು ಅವನಿಗೆ ಉಡುಗೊರೆಯನ್ನು ನೀಡುತ್ತೇನೆ.'\n",
    "]\n",
    "\n",
    "output_sanskrit= [\n",
    " 'यदा अहं बालकः आसीत्, तदा प्रतिदिनं उद्यानं गच्छामि स्म।',\n",
    " 'तस्य समीपे बहूनि पुरातनानि पुस्तकानि सन्ति, यानि सः स्वपितृभ्यः उत्तराधिकाररूपेण प्राप्तवान्।',\n",
    " 'मम समस्यायाः निराकरणं कथं करणीयम् इति अहं कल्पयितुं न शक्नोमि।',\n",
    " 'सा अतीव परिश्रमी, बुद्धिमती च अस्ति, अतः सा सर्वाणि उत्तमानि अङ्कानि प्राप्नोत्।',\n",
    " 'वयं गतसप्ताहे नूतनं चलच्चित्रं दृष्टवन्तः, यत् अत्यन्तं प्रेरकम् आसीत्।',\n",
    " 'तस्मिन् समये यदि त्वं मह्यं मिलितवान् तर्हि वयं भोजनार्थं बहिः गमिष्यामः स्म।',\n",
    " 'सा नूतनां शाटिकां क्रेतुं भगिन्या सह विपणिं गतवती।',\n",
    " 'अग्रिमे मासे सः मातामहीगृहं गमिष्यति इति राज् अवदत्।',\n",
    " 'सर्वे बालकाः उत्सवे विनोदं कुर्वन्तः, अनेकानि मधुराणि खादन्तः च आसन्।',\n",
    " 'मम मित्रः तस्य जन्मदिनसमारोहे आमन्त्रयत्, अहं तं उपहारं ददामि।'\n",
    "]\n",
    "\n",
    "# Create a variable to store the directory path\n",
    "AI4_BHARAT= \"ai4bharat/indictrans2-indic-indic-1B\"; direction=\"/content/IndicTrans2/huggingface_interface/IndicTransTokenizer/IndicTransTokenizer/indic-indic/\";\n",
    "\n",
    "# getting tokenizer and model by passing arg. to initialize_model_and_tokenizer function\n",
    "Tokenizer, model= initialize_model_and_tokenizer( ckpt_dir=AI4_BHARAT, direction= my_direction, quantization=\"4-bit\"  )\n",
    "\n",
    "indic= IndicProcessor(inference=True)\n",
    "\n",
    "# Choose the source langauge as English and target language as Hindi.\n",
    "lan_src_3= \"kan_Knda\";\n",
    "lan_tar_3=\"san_Deva\"\n",
    "\n",
    "# Find target translation using the batch_translate function with arg: input_sentences, src_lang, tgt_lang, model, tokenizer, ip\n",
    "target_trans_3= batch_translate( input_kannada , lan_src_3, lan_tar_3, model, Tokenizer, indic  )\n",
    "\n",
    "# flush the models to free the GPU memory\n",
    "del Tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-WqypeHHu4m",
    "outputId": "6d19e66b-2553-4d2e-cdb5-8d01ba970686"
   },
   "outputs": [],
   "source": [
    "target_trans_3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
